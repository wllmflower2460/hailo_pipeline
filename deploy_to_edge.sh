#!/bin/bash
set -e

# Automated Deployment: GPUSRV â†’ Edge Platform
# Deploy 72.13% TCN-VAE model to EdgeInfer on Raspberry Pi 5 + Hailo-8
# Uses Tailscale mesh networking for secure cross-machine deployment

# Configuration from AI handoff document
GPUSRV_HOST="gpusrv.tailfdc654.ts.net"
EDGE_HOST="192.168.50.88" 
EDGE_IP="192.168.50.88"

# Deployment paths
LOCAL_ARTIFACTS_DIR="$(pwd)/artifacts"
EDGE_DEPLOY_DIR="/opt/edgeinfer/artifacts"
EDGE_USER="pi"

# Model information
MODEL_VERSION="v72pct"
MODEL_ACCURACY="72.13%"
HEF_FILE="tcn_encoder_${MODEL_VERSION}.hef"
METADATA_FILE="deployment_metadata.json"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

warning() {
    echo -e "${YELLOW}âš ï¸ $1${NC}"
}

error() {
    echo -e "${RED}âŒ $1${NC}"
    exit 1
}

print_header() {
    echo "================================================================================"
    echo -e "${BLUE}ðŸš€ EdgeInfer Model Deployment Pipeline${NC}"
    echo "   Model: TCN-VAE Encoder ${MODEL_ACCURACY} accuracy"
    echo "   Source: GPUSRV ($(hostname))"
    echo "   Target: EdgeInfer on ${EDGE_HOST}"
    echo "   Architecture: GPUSRV â†’ Tailscale â†’ Edge Platform"
    echo "================================================================================"
}

check_prerequisites() {
    log "Checking deployment prerequisites..."
    
    # Check if running on correct source machine
    if [[ ! -f "${LOCAL_ARTIFACTS_DIR}/${HEF_FILE}" ]]; then
        error "HEF file not found: ${LOCAL_ARTIFACTS_DIR}/${HEF_FILE}"
    fi
    
    if [[ ! -f "${LOCAL_ARTIFACTS_DIR}/${METADATA_FILE}" ]]; then
        error "Deployment metadata not found: ${LOCAL_ARTIFACTS_DIR}/${METADATA_FILE}"
    fi
    
    # Check Tailscale connectivity
    if ! ping -c 1 "${EDGE_HOST}" > /dev/null 2>&1; then
        error "Cannot reach Edge platform via Tailscale: ${EDGE_HOST}"
    fi
    
    # Check SSH access
    if ! ssh -o ConnectTimeout=10 -o BatchMode=yes "${EDGE_USER}@${EDGE_HOST}" "echo 'SSH connection successful'" > /dev/null 2>&1; then
        error "SSH access to Edge platform failed. Check SSH keys and permissions."
    fi
    
    success "Prerequisites check passed"
}

backup_current_model() {
    log "Creating backup of current model on Edge platform..."
    
    ssh "${EDGE_USER}@${EDGE_HOST}" "
        if [[ -f '${EDGE_DEPLOY_DIR}/current_model.hef' ]]; then
            backup_name=\"backup_\$(date +%Y%m%d_%H%M%S).hef\"
            mv '${EDGE_DEPLOY_DIR}/current_model.hef' '${EDGE_DEPLOY_DIR}/\${backup_name}'
            echo 'Current model backed up as: \${backup_name}'
        else
            echo 'No current model found - this appears to be initial deployment'
        fi
        
        # Ensure deployment directory exists
        sudo mkdir -p '${EDGE_DEPLOY_DIR}'
        sudo chown ${EDGE_USER}:${EDGE_USER} '${EDGE_DEPLOY_DIR}'
    "
    
    success "Model backup completed"
}

copy_artifacts_to_edge() {
    log "Copying model artifacts to Edge platform..."
    
    # Calculate file sizes for progress tracking
    local hef_size=$(du -h "${LOCAL_ARTIFACTS_DIR}/${HEF_FILE}" | cut -f1)
    local metadata_size=$(du -h "${LOCAL_ARTIFACTS_DIR}/${METADATA_FILE}" | cut -f1)
    
    log "  Copying ${HEF_FILE} (${hef_size}) ..."
    if scp -o ConnectTimeout=30 "${LOCAL_ARTIFACTS_DIR}/${HEF_FILE}" "${EDGE_USER}@${EDGE_HOST}:${EDGE_DEPLOY_DIR}/${HEF_FILE}"; then
        success "HEF file copied successfully"
    else
        error "Failed to copy HEF file"
    fi
    
    log "  Copying ${METADATA_FILE} (${metadata_size}) ..."
    if scp -o ConnectTimeout=30 "${LOCAL_ARTIFACTS_DIR}/${METADATA_FILE}" "${EDGE_USER}@${EDGE_HOST}:${EDGE_DEPLOY_DIR}/${METADATA_FILE}"; then
        success "Metadata file copied successfully"
    else
        error "Failed to copy metadata file"
    fi
    
    # Create symlink to current model for EdgeInfer
    ssh "${EDGE_USER}@${EDGE_HOST}" "
        cd '${EDGE_DEPLOY_DIR}' && 
        ln -sf '${HEF_FILE}' 'current_model.hef' &&
        echo 'Symlink created: current_model.hef -> ${HEF_FILE}'
    "
    
    success "All artifacts copied and linked successfully"
}

update_edgeinfer_config() {
    log "Updating EdgeInfer configuration for new model..."
    
    # Update Docker Compose environment variables
    ssh "${EDGE_USER}@${EDGE_HOST}" "
        cd /opt/edgeinfer
        
        # Backup current configuration
        if [[ -f docker-compose.yml ]]; then
            cp docker-compose.yml docker-compose.yml.backup.\$(date +%Y%m%d_%H%M%S)
        fi
        
        # Update environment variables for new model
        export MODEL_VERSION='${MODEL_VERSION}'
        export MODEL_ACCURACY='${MODEL_ACCURACY}'
        export HEF_PATH='${EDGE_DEPLOY_DIR}/current_model.hef'
        
        # Verify HEF file exists and is readable
        if [[ -f '${EDGE_DEPLOY_DIR}/current_model.hef' ]]; then
            echo 'HEF file verified: \$(ls -lh ${EDGE_DEPLOY_DIR}/current_model.hef)'
        else
            echo 'ERROR: HEF file not found after copy'
            exit 1
        fi
        
        echo 'EdgeInfer configuration updated for model ${MODEL_VERSION}'
    "
    
    success "EdgeInfer configuration updated"
}

restart_edgeinfer_services() {
    log "Restarting EdgeInfer services with new model..."
    
    ssh "${EDGE_USER}@${EDGE_HOST}" "
        cd /opt/edgeinfer
        
        # Stop existing services
        echo 'Stopping EdgeInfer services...'
        docker-compose down --timeout 30 || true
        
        # Wait for cleanup
        sleep 5
        
        # Start services with new model
        echo 'Starting EdgeInfer services with new model...'
        docker-compose up -d
        
        # Wait for services to initialize
        echo 'Waiting for services to initialize...'
        sleep 15
        
        # Check service status
        docker-compose ps
    "
    
    success "EdgeInfer services restarted"
}

validate_deployment() {
    log "Validating deployment and service health..."
    
    # Wait for services to be fully ready
    sleep 10
    
    local max_retries=6
    local retry_count=0
    local health_check_passed=false
    
    while [[ ${retry_count} -lt ${max_retries} ]]; do
        log "Health check attempt $((retry_count + 1))/${max_retries}..."
        
        if ssh "${EDGE_USER}@${EDGE_HOST}" "curl -s -f http://localhost:9000/healthz > /dev/null 2>&1"; then
            health_check_passed=true
            break
        fi
        
        retry_count=$((retry_count + 1))
        if [[ ${retry_count} -lt ${max_retries} ]]; then
            log "Health check failed, retrying in 10 seconds..."
            sleep 10
        fi
    done
    
    if [[ "${health_check_passed}" == "true" ]]; then
        success "EdgeInfer health check passed"
    else
        error "EdgeInfer health check failed after ${max_retries} attempts"
    fi
    
    # Test the encode endpoint with sample data
    log "Testing /encode endpoint with sample IMU data..."
    
    ssh "${EDGE_USER}@${EDGE_HOST}" "
        # Create test IMU data
        cat > /tmp/test_imu.json << 'EOF'
{
  \"imu_data\": [
    [0.12, -0.08, 9.78, 0.002, -0.001, 0.003, 22.4, -8.7, 43.2],
    [0.15, -0.05, 9.82, 0.001, -0.002, 0.004, 22.1, -8.9, 43.5]
  ]
}
EOF
        
        # Test the endpoint
        response=\$(curl -s -X POST http://localhost:9000/encode \\
                        -H 'Content-Type: application/json' \\
                        -d @/tmp/test_imu.json)
        
        if [[ \$? -eq 0 ]] && [[ -n \"\${response}\" ]]; then
            echo 'Encode endpoint test successful:'
            echo \"\${response}\" | head -c 200
            echo ''
        else
            echo 'Encode endpoint test failed'
            exit 1
        fi
        
        # Cleanup
        rm -f /tmp/test_imu.json
    "
    
    success "Endpoint validation passed"
}

generate_deployment_report() {
    log "Generating deployment report..."
    
    local report_file="deployment_report_$(date +%Y%m%d_%H%M%S).json"
    
    cat > "${report_file}" << EOF
{
  "deployment_report": {
    "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "model_info": {
      "version": "${MODEL_VERSION}",
      "accuracy": "${MODEL_ACCURACY}",
      "improvement": "+25.1% over baseline",
      "hef_file": "${HEF_FILE}"
    },
    "deployment_path": {
      "source": "$(hostname) (GPUSRV)",
      "target": "${EDGE_HOST} (Edge Platform)",
      "transport": "Tailscale mesh networking",
      "method": "SSH/SCP automated pipeline"
    },
    "validation_results": {
      "health_check": "PASSED",
      "encode_endpoint": "PASSED",
      "service_restart": "SUCCESSFUL"
    },
    "performance_expectations": {
      "latency_p95_ms": 50,
      "throughput_req_sec": 250,
      "memory_usage_mb": 512,
      "note": "Performance validation pending on real hardware"
    },
    "next_steps": [
      "Run performance benchmarks on Edge platform",
      "Monitor EdgeInfer metrics and logs",
      "Validate integration with active learning pipeline",
      "Update production documentation"
    ]
  }
}
EOF
    
    success "Deployment report saved: ${report_file}"
    log "Report contents preview:"
    head -20 "${report_file}"
}

rollback_deployment() {
    error "Deployment failed - initiating rollback..."
    
    ssh "${EDGE_USER}@${EDGE_HOST}" "
        cd '${EDGE_DEPLOY_DIR}'
        
        # Find most recent backup
        latest_backup=\$(ls -t backup_*.hef 2>/dev/null | head -1)
        
        if [[ -n \"\${latest_backup}\" ]]; then
            echo 'Rolling back to: \${latest_backup}'
            ln -sf \"\${latest_backup}\" 'current_model.hef'
            
            cd /opt/edgeinfer
            docker-compose restart
            
            echo 'Rollback completed'
        else
            echo 'No backup found - manual intervention required'
        fi
    "
}

# Trap to handle failures and attempt rollback
trap 'rollback_deployment' ERR

main() {
    print_header
    
    check_prerequisites
    backup_current_model
    copy_artifacts_to_edge
    update_edgeinfer_config
    restart_edgeinfer_services
    validate_deployment
    generate_deployment_report
    
    echo ""
    echo "================================================================================"
    success "ðŸŽ‰ Deployment completed successfully!"
    echo "   Model: TCN-VAE ${MODEL_ACCURACY} accuracy"
    echo "   Platform: EdgeInfer on ${EDGE_HOST}"
    echo "   Status: READY FOR PRODUCTION"
    echo "================================================================================"
    echo ""
    echo "ðŸ“‹ Next Steps:"
    echo "   1. Run performance benchmarks: ./validate_performance.py"
    echo "   2. Monitor EdgeInfer logs: docker-compose logs -f"
    echo "   3. Test integration with active learning pipeline"
    echo "   4. Update production monitoring dashboards"
    echo ""
}

# Handle command line arguments
case "${1:-deploy}" in
    "deploy")
        main
        ;;
    "rollback")
        rollback_deployment
        ;;
    "test")
        log "Running deployment test (dry run)..."
        check_prerequisites
        success "Deployment test passed - ready for actual deployment"
        ;;
    *)
        echo "Usage: $0 [deploy|rollback|test]"
        echo "  deploy   - Deploy model to Edge platform (default)"
        echo "  rollback - Rollback to previous model"
        echo "  test     - Test deployment prerequisites"
        exit 1
        ;;
esac